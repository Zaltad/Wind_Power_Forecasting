{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"collapsed_sections":["9-FO_FFTqfqj","ztW-os_4TQ-2","u3JjaZCDTWN8","Ksa7d2pjTO86","ekMofq1duzy3","Gndcntqt69-N","lgnlFVTZ7Bec","tG4ejXt-Gi7j","YHkEUJJRGnTf"],"provenance":[]},"gpuClass":"standard","kaggle":{"accelerator":"none","dataSources":[{"sourceId":13251348,"sourceType":"datasetVersion","datasetId":8396800}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T06:29:13.997965Z","iopub.execute_input":"2025-10-07T06:29:13.998188Z","iopub.status.idle":"2025-10-07T06:29:16.226627Z","shell.execute_reply.started":"2025-10-07T06:29:13.998168Z","shell.execute_reply":"2025-10-07T06:29:16.225750Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/wind-farm-power-forecasting/85b5cb4eea5a4f259766f42a448e2c04a7499c43e1ae4cc28fbdee8e087e2385\n/kaggle/input/wind-farm-power-forecasting/e927ce742c884955bf2a667929d36b2ef41c572cd6e245fa86257ecc2f7be7bc\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/wind-farm-power-forecasting/e927ce742c884955bf2a667929d36b2ef41c572cd6e245fa86257ecc2f7be7bc\")\ndf1 = pd.read_csv(\"/kaggle/input/wind-farm-power-forecasting/85b5cb4eea5a4f259766f42a448e2c04a7499c43e1ae4cc28fbdee8e087e2385\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T06:30:54.410758Z","iopub.execute_input":"2025-10-07T06:30:54.411492Z","iopub.status.idle":"2025-10-07T06:31:03.142368Z","shell.execute_reply.started":"2025-10-07T06:30:54.411466Z","shell.execute_reply":"2025-10-07T06:31:03.141661Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"print(df)\nprint(df1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-07T06:31:06.426993Z","iopub.execute_input":"2025-10-07T06:31:06.427326Z","iopub.status.idle":"2025-10-07T06:31:06.446603Z","shell.execute_reply.started":"2025-10-07T06:31:06.427304Z","shell.execute_reply":"2025-10-07T06:31:06.445631Z"}},"outputs":[{"name":"stdout","text":"     TurbID          x           y\n0         1  3349.8515  5939.23193\n1         2  3351.0017  6416.64673\n2         3  3314.7797  6892.18395\n3         4  3352.0940  7366.14203\n4         5  3355.3420  7841.20175\n..      ...        ...         ...\n129     130    12.6509  4814.60040\n130     131    23.3458  5284.65439\n131     132    62.6774  5749.90633\n132     133    78.4309  6231.32903\n133     134    11.3385  6713.46517\n\n[134 rows x 3 columns]\n         TurbID  Day Tmstamp  Wspd  Wdir   Etmp   Itmp    Ndir  Pab1  Pab2  \\\n0             1    1   00:00   NaN   NaN    NaN    NaN     NaN   NaN   NaN   \n1             1    1   00:10  6.17 -3.99  30.73  41.80   25.92  1.00  1.00   \n2             1    1   00:20  6.27 -2.18  30.60  41.63   20.91  1.00  1.00   \n3             1    1   00:30  6.42 -0.73  30.52  41.52   20.91  1.00  1.00   \n4             1    1   00:40  6.25  0.89  30.49  41.38   20.91  1.00  1.00   \n...         ...  ...     ...   ...   ...    ...    ...     ...   ...   ...   \n4727515     134  245   23:10  7.79  2.80  -0.07   3.95  216.51  6.03  6.03   \n4727516     134  245   23:20  8.06  4.39   0.23   3.94  216.51  5.81  5.81   \n4727517     134  245   23:30  8.08  2.28  -0.16   4.15  216.51  0.68  0.68   \n4727518     134  245   23:40  8.46  0.80  -0.14   4.32  216.51  0.02  0.02   \n4727519     134  245   23:50  8.68  0.52  -0.06   4.39  216.51  0.01  0.01   \n\n         Pab3    Prtv     Patv  \n0         NaN     NaN      NaN  \n1        1.00   -0.25   494.66  \n2        1.00   -0.24   509.76  \n3        1.00   -0.26   542.53  \n4        1.00   -0.23   509.36  \n...       ...     ...      ...  \n4727515  6.03 -111.69   601.44  \n4727516  5.81  -72.67   673.79  \n4727517  0.68 -118.70   999.36  \n4727518  0.02  -58.12  1100.89  \n4727519  0.01  -44.75  1181.49  \n\n[4727520 rows x 13 columns]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Lab 1.1: Graph Regularization\n\nIn this lab, you will learn how to perform graph-based machine learning via regularization techniques.\nThe specific objectives are:\n\n*   Implement different graph-based regularization techniques to perform node-wise signal regression.\n*   Analyze the trade-off between fitting and regularization.\n*   Explain the perfromance of particular regularizer.\n\n**Completion requirements**\n\n*   Showing the graph sparsity as a function of abstract network hyper-parameters.\n*   Implementing and analyzing two regularizers for signal denosing and reconstruction. \n \n\n","metadata":{}},{"cell_type":"markdown","source":"## Dataset and problem definition\n\nTo achieve the above objectives, we will work with a real-world weather dataset called **Molene**.\nThis dataset contains weather temperature over 32 distinct stations in France recorded for a month with hourly resolution.\nWe will treat each time instant as a graph signal and aim to recover it from noisy measurments and signals with missing values.\nFor this, we will compare two regularization techniques:\n*   Tikhonov regularizer\n$$\n\\hat{\\textbf{x}} = \\text{arg}\\min_{\\textbf{x}} \\|\\textbf{y} - \\textbf{x}\\|_2^2 + \\alpha \\textbf{x}^T\\textbf{L}\\textbf{x}\n$$\n\n*   Trend filtering.\n$$\n\\hat{\\textbf{x}} = \\text{arg}\\min_{\\textbf{x}} \\|\\textbf{y} - \\textbf{x}\\|_2^2 + \\beta \\|\\textbf{B}^T\\textbf{x}\\|_1,\n$$\nwhere $\\textbf{B}$ is the indcidence matrix of the graph.","metadata":{}},{"cell_type":"markdown","source":"## Libraries\n\n* Numpy\n* Pandas\n* PyGSP or NetwrokX (or any other viable libraries)\n* Scikit-learn\n* Matplotlib\n* CVXPy and CVXOPT (or any other optimization solver library)","metadata":{}},{"cell_type":"code","source":"%pip install PyGSP","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pygsp import graphs, plotting\nimport matplotlib.pyplot as plt\nimport cvxpy as cp\nimport cvxopt as cvxopt","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Building the graph\n\nWe can treat each sensor as a node of a graph and the temperatures as signals over these nodes.\nThese sensors have also metadata such as their geolocation.\nWe can therefore build an abstract network connecting them.\nThis network can for instance be build using these metadata or using a portion of the time series and connecting nodes based on their statistical dependencies in them (e.g. Pearson correlation).\nIn either case, you could use different criteria to connect the nodes such as $k$-nearest neighbors, $\\epsilon$-ball graph, etc.\n*It is up to you to build any graph from any data* ","metadata":{}},{"cell_type":"markdown","source":"### Task 1\n\nBuild a **connected** and **sparse** graph between sensors.\nChoose your hyperparameters to achieve at least 80% sparsity ($\\frac{\\text{zeros of } \\textbf{A}}{N^2}$).\nIf you cannot ensure a connected graph with such a sparsity factor it can also be less sparse.\nTune your hyper parameters accordingly.","metadata":{}},{"cell_type":"code","source":"## Reading metadata of the stations\nstations_metadata = pd.read_csv('lab1_molene/weather_stations_filtered_Molene.csv',index_col=0)\nstations_metadata","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## extracting the coordinates for each station from the metadata => these coordinates can be treated as distance\ncoordinates_df = stations_metadata.iloc[:,-3:]  \ncoordinates_df = coordinates_df - coordinates_df.mean() # => Removing mean to have more tangible coordinates\ncoordinates = coordinates_df.to_numpy()\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# add your code to build the graph. Use hyperparameter such that the sparsity factor is greater than 80%.\n# You can PyGSP or NetwrokX pakcage for this to have predefined graph builders.","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Now build graphs by varying the the chosen hyperparameter and plot the sparsity of the graph with respect to the hyperparameter.","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ðŸ•µ <font color='289C4E'>Question 1<font><a class='anchor' id='top'></a>\n* What type of graph did you use and what is the hyperparameter of it?\n* How does the chosen hyperparameter effect the graph sparsity? \\\n**Note:** Make sure the graph remains connected.","metadata":{}},{"cell_type":"markdown","source":"**Answer**:\n<font color = 'red'>\nWrite your answer here ...","metadata":{}},{"cell_type":"markdown","source":"## Missing measurements\n\nConsider now that the signal is noiseless but it is observed only in a portion of the nodes: $\\textbf{y} = \\textbf{P} \\textbf{x}$, where $\\textbf{P} \\in \\mathbb{R}^{M \\times N}$ is the sampling matrix collecting $M$ out of the possible $N$ samples. ","metadata":{}},{"cell_type":"markdown","source":"### Task 2\n\nTaking the best regularization weights from the above exercise, show the rNMSE of the recovered signal for both regularizers and for each value of $M \\in \\{3,9,15,21,27\\}$.","metadata":{}},{"cell_type":"code","source":"## add your code here\n## Generate the data with missing values (or only indices).","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Add your code here\n## solve and evaluate for Tikhonov regularizer","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Add your code here\n## solve and evaluate for the regularizer of your choice","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ðŸ•µ <font color='289C4E'>Question 2<font><a class='anchor' id='top'></a>\n*  What would you conclude about the behaviour of the two regularizers?","metadata":{}},{"cell_type":"markdown","source":"**Answer**:\n<font color = 'red'>\nWrite your answer here ...","metadata":{}},{"cell_type":"markdown","source":"# Optional Exercises\n### This part of the assignment is **optional**. It does not count toward the completion of this assignment. Only do it if you are interested and can spare the time","metadata":{}},{"cell_type":"markdown","source":"## Noisy measurements\n\nLet $e$ be the average energy of the graph signals in the dataset.\n$$\ne = \\frac{1}{m} \\sum_{i=1}^m \\|\\textbf{x}_i\\|_2^2,\n$$\nwhere $m$ is the number of data points.\nGenerate $m$ noisy graph signal $\\textbf{y} = \\textbf{x} + \\textbf{n}$ where $\\textbf{n}$ is a zero-mean Gaussian noise $\\textbf{n} \\sim \\mathcal{N}(0,Ïƒ^2\\textbf{I})$.\nConsider $\\sigma^2 = e/2$.","metadata":{}},{"cell_type":"code","source":"## loading the data\ntimeseries_data = pd.read_csv('lab1_molene/filtered_data_Molene.csv', index_col = 'date', parse_dates = True)\ntimeseries_data = timeseries_data - timeseries_data.mean() # => removing mean from data","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = timeseries_data.to_numpy().transpose()  # => transpose the data so we have each column as a graph signal\n\ne = np.sum(np.square(x))/x.shape[1] # computing average energy\n\nsigma = e/x.shape[0]/2\nn = np.random.multivariate_normal(np.zeros(x.shape[0]),sigma*np.eye(x.shape[0]),size=x.shape[1]).transpose() # => generating noise\n\ny = x + n   # adding to noise to synthesize noisy observations","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Task 3\n\nUse the Tikhonov regularizer for a choice of $\\alpha > 0$ to recover signal $\\textbf{x}$ from the measurements $\\textbf{y}$.\nProvide the signal recovery metric root normalized mean square error (rNMSE)\n$$\n\\text{rNMSE} = \\left(\\frac{\\sum_{i=1}^m \\|\\hat{\\textbf{x}}_i-\\textbf{x}_i\\|_2^2}{\\sum_{i=1}^m\\|\\textbf{y}_i\\|_2^2}\n\\right)^{0.5}\n$$","metadata":{}},{"cell_type":"code","source":"## set the regularizer coefficient\nalpha = ... \n\n## exploit the graph Laplacian (if you are using pygsp, convert it to dense format from sparse for further computations(use .todense()).\nL = ...\n\n## write down the closed form solution for Tikhonov regularizer\nx_hat = np.matmul(np.linalg.inv(...),y) \n\nrnmse = np.sqrt(np.square(x_hat-x).mean())/y.std()  # rnmse definition\n\nprint(f\"The rNMSE is: {np.round(rnmse,4)}\")\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ðŸ•µ <font color='289C4E'>Question 3<font><a class='anchor' id='top'></a>\n\nIllustrate rNMSE as a function of $\\alpha \\in [0,10]$. What do you conclude about the role of the regularizer?\n","metadata":{}},{"cell_type":"code","source":"## Add your code here","metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"**Answer**:\n<font color = 'red'>\nWrite your answer here ...","metadata":{}},{"cell_type":"markdown","source":"### ðŸ•µ <font color='289C4E'>Question 4<font><a class='anchor' id='top'></a>\n\nConsider now different noisy scenarios, $\\sigma^2 = e/10$ and $\\sigma^2 = e$. Add the respective lines into your plot. What do you conclude about the role of the regularizer?","metadata":{}},{"cell_type":"code","source":"## Add your code here","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Answer**:\n<font color = 'red'>\nWrite your answer here ...","metadata":{}},{"cell_type":"markdown","source":"### Task 4\n\nImplement trend filtering regularizer and compare the performance with the Tikhonov regularizer for $\\sigma^2 = e/2$.","metadata":{}},{"cell_type":"code","source":"## Add your code here.\n## You may need an optimization solver if your chosen regularizer does not have a closed form solution.","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ðŸ•µ <font color='289C4E'>Question 5<font><a class='anchor' id='top'></a>\n\nWhy and when does one regularizer performs better than the other?","metadata":{}},{"cell_type":"markdown","source":"**Answer**:\n<font color = 'red'>\nWrite your answer here ...","metadata":{}}]}